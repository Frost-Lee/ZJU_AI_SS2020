{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDrv2IGd3oVp",
        "colab_type": "code",
        "outputId": "e001274a-9be9-4a5f-d4b2-ac8ed5ee6c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install gpustat\n",
        "!gpustat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1t-pXCT9eEN",
        "colab_type": "code",
        "outputId": "9a885c89-bbf9-4cdf-9975-ed484d07071b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "from tensorflow import keras\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2z1iIT8bZRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STATES_FILE_PATH = '/content/gdrive/My Drive/data_source/reversi_zero/states.npy'\n",
        "POLICIES_FILE_PATH = '/content/gdrive/My Drive/data_source/reversi_zero/policies.npy'\n",
        "VALUES_FILE_PATH = '/content/gdrive/My Drive/data_source/reversi_zero/values.npy'\n",
        "\n",
        "MODEL_ARCHIVE_PATH = '/content/gdrive/My Drive/data_source/reversi_zero/models/'\n",
        "LOG_PATH = '/content/gdrive/My Drive/data_source/reversi_zero/log/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TShPNsrv4jvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NNModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self._create_model()\n",
        "    \n",
        "    def predict(self, state):\n",
        "        result = self.model.predict(np.array([state]))\n",
        "        return result[0][0], result[1][0]\n",
        "    \n",
        "    def fit(self, states, policies, values, batch_size=None, epochs=1, callbacks=[]):\n",
        "        self.model.fit(\n",
        "            x=states,\n",
        "            y=[policies, values],\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "    \n",
        "    def save(self, path):\n",
        "        self.model.save(path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        loaded_model = keras.models.load_model(path)\n",
        "        self.model.set_weights(loaded_model.get_weights())\n",
        "    \n",
        "    def clone(self):\n",
        "        cloned_model = NNModel()\n",
        "        cloned_model.model.set_weights(self.model.get_weights())\n",
        "        return cloned_model\n",
        "\n",
        "    def _create_model(self):\n",
        "        model_input = keras.layers.Input(\n",
        "            shape=(8, 8, 2),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        \n",
        "        # Residual blocks\n",
        "        layer = NNModel._conv_batchnorm(\n",
        "            filters=128, \n",
        "            kernel_size=(3, 3), \n",
        "            padding='same', \n",
        "            kernel_regularizer=keras.regularizers.l2(1e-4), \n",
        "            activation='relu'\n",
        "        )(model_input)\n",
        "        for _ in range(16):\n",
        "            layer = NNModel._residual_block(\n",
        "                filters=128, \n",
        "                kernel_size=(3, 3), \n",
        "                padding='same', \n",
        "                kernel_regularizer=keras.regularizers.l2(1e-4)\n",
        "            )(layer)\n",
        "        \n",
        "        # Value generation\n",
        "        value = layer\n",
        "        value = NNModel._conv_batchnorm(\n",
        "            filters=1, \n",
        "            kernel_size=(1, 1), \n",
        "            kernel_regularizer=keras.regularizers.l2(1e-4), \n",
        "            activation='relu'\n",
        "        )(value)\n",
        "        value = keras.layers.Flatten()(value)\n",
        "        value = keras.layers.Dense(\n",
        "            units=64,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=keras.regularizers.l2(1e-4)\n",
        "        )(value)\n",
        "        value = keras.layers.Dense(\n",
        "            units=1,\n",
        "            activation='tanh',\n",
        "            name='value'\n",
        "        )(value)\n",
        "\n",
        "        # Policy generation\n",
        "        policy = layer\n",
        "        policy = NNModel._conv_batchnorm(\n",
        "            filters=2, \n",
        "            kernel_size=(1, 1), \n",
        "            kernel_regularizer=keras.regularizers.l2(1e-4), \n",
        "            activation='relu'\n",
        "        )(policy)\n",
        "        policy = keras.layers.Flatten()(policy)\n",
        "        policy = keras.layers.Dense(\n",
        "            units=8 * 8,\n",
        "            activation='softmax',\n",
        "            name='policy'\n",
        "        )(policy)\n",
        "\n",
        "        # Model assemble\n",
        "        model = keras.models.Model(inputs=[model_input], outputs=[policy, value])\n",
        "        self.model = model\n",
        "        self._compile()\n",
        "    \n",
        "    def _compile(self):\n",
        "        self.model.compile(\n",
        "            optimizer=keras.optimizers.Adam(),\n",
        "            loss=[keras.losses.categorical_crossentropy, keras.losses.mean_squared_error],\n",
        "            loss_weights=[0.5, 0.5]\n",
        "        )\n",
        "    \n",
        "    @staticmethod\n",
        "    def _conv_batchnorm(filters, kernel_size, padding='valid', kernel_regularizer=None, activation='linear'):\n",
        "        def structure(input_tensor):\n",
        "            layer = keras.layers.Conv2D(\n",
        "                filters=filters,\n",
        "                kernel_size=kernel_size,\n",
        "                padding=padding,\n",
        "                kernel_regularizer=kernel_regularizer\n",
        "            )(input_tensor)\n",
        "            layer = keras.layers.BatchNormalization()(layer)\n",
        "            layer = keras.layers.Activation(activation)(layer)\n",
        "            return layer\n",
        "        return structure\n",
        "    \n",
        "    @staticmethod\n",
        "    def _residual_block(filters, kernel_size, padding='valid', kernel_regularizer=None):\n",
        "        def structure(input_tensor):\n",
        "            residual = input_tensor\n",
        "            layer = NNModel._conv_batchnorm(\n",
        "                filters=filters, \n",
        "                kernel_size=kernel_size, \n",
        "                padding=padding, \n",
        "                kernel_regularizer=keras.regularizers.l2(1e-4),\n",
        "                activation='relu'\n",
        "            )(input_tensor)\n",
        "            layer = NNModel._conv_batchnorm(\n",
        "                filters=filters, \n",
        "                kernel_size=kernel_size, \n",
        "                padding=padding, \n",
        "                kernel_regularizer=keras.regularizers.l2(1e-4),\n",
        "            )(layer)\n",
        "            layer = keras.layers.Add()([residual, layer])\n",
        "            layer = keras.layers.Activation('relu')(layer)\n",
        "            return layer\n",
        "        return structure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywPBavSmkumo",
        "colab_type": "code",
        "outputId": "2c74bb2e-cbfb-46a8-a6a8-b6286c858591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "states, policies, values = np.load(STATES_FILE_PATH), np.load(POLICIES_FILE_PATH), np.load(VALUES_FILE_PATH)\n",
        "\n",
        "def augment(states, policies, values):\n",
        "    states = np.concatenate([\n",
        "        states, \n",
        "        states[:, ::-1, ::-1, :], \n",
        "        states[:, ::-1, :, :], \n",
        "        states[:, :, ::-1, :],\n",
        "        np.rot90(states, k=1, axes=(1, 2)),\n",
        "        np.rot90(states, k=2, axes=(1, 2)), \n",
        "        np.rot90(states, k=3, axes=(1, 2))\n",
        "    ])\n",
        "    policies = np.reshape(policies, (policies.shape[0], 8, 8))\n",
        "    policies = np.concatenate([\n",
        "        policies,\n",
        "        policies[:, ::-1, ::-1],\n",
        "        policies[:, ::-1, :],\n",
        "        policies[:, :, ::-1],\n",
        "        np.rot90(policies, k=1, axes=(1, 2)),\n",
        "        np.rot90(policies, k=2, axes=(1, 2)), \n",
        "        np.rot90(policies, k=3, axes=(1, 2))\n",
        "    ])\n",
        "    policies = np.reshape(policies, (policies.shape[0], 8 * 8))\n",
        "    values = np.concatenate([values] * 7)\n",
        "    return states, policies, values\n",
        "\n",
        "states, policies, values = augment(states, policies, values)\n",
        "print(states.shape, policies.shape, values.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9POU6QDldC2Z",
        "colab_type": "code",
        "outputId": "0a6627ab-aae2-4b85-c696-a6da0f39df79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = NNModel()\n",
        "model.fit(\n",
        "    states, \n",
        "    policies,\n",
        "    values,\n",
        "    batch_size=256, \n",
        "    epochs=64,\n",
        "    callbacks=[\n",
        "        keras.callbacks.LearningRateScheduler(lambda ei, lr: lr / 2.0 if ei > 0 and (ei / 16).is_integer() else lr),\n",
        "        keras.callbacks.TensorBoard(log_dir=LOG_PATH, update_freq=64),\n",
        "        keras.callbacks.ModelCheckpoint(MODEL_ARCHIVE_PATH + 'model_checkpoint_{epoch:02d}.hdf5', period=8)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXIdxtbHD2LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "full_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}