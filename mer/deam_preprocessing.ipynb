{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALENCE_SOURCE_PATH = '/Users/canchel/Desktop/Archive/annotations/annotations averaged per song/dynamic (per second annotations)/valence.csv'\n",
    "AROUSAL_SOURCE_PATH = '/Users/canchel/Desktop/Archive/annotations/annotations averaged per song/dynamic (per second annotations)/arousal.csv'\n",
    "\n",
    "METADATA_2013_PATH = '/Users/canchel/Desktop/metadata/metadata_2013.csv'\n",
    "\n",
    "FEATURE_FILES_DIR = '/Users/canchel/Desktop/Archive/features'\n",
    "\n",
    "ARCHIVE_OUTPUT_PATH = '/Users/canchel/Desktop/deam_samples.hdf5'\n",
    "\n",
    "NORMALIZED_ARCHIVE_OUTPUT_PATH = '/Users/canchel/Desktop/normalized_deam_samples.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_df = pd.read_csv(VALENCE_SOURCE_PATH).set_index('song_id')\n",
    "arousal_df = pd.read_csv(AROUSAL_SOURCE_PATH).set_index('song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "va_dicts = {si : (dict(valence_df.loc[si].dropna()), dict(arousal_df.loc[si].dropna())) for si in valence_df.index.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_2013_df = pd.read_csv(METADATA_2013_PATH).set_index('song_id')\n",
    "\n",
    "def t_shift(song_index):\n",
    "    if song_index <= 1000:\n",
    "        start_min, start_sec = tuple([*map(int, str(metadata_2013_df.loc[song_index]['start of the segment (min.sec)']).split('.'))])\n",
    "        return start_min * 60 + start_sec - 1\n",
    "    elif 1000 < song_index <= 2000:\n",
    "        return -1\n",
    "    elif 2000 < song_index:\n",
    "        return -1\n",
    "\n",
    "with h5py.File(ARCHIVE_OUTPUT_PATH) as out_file:\n",
    "    for song_index in va_dicts.keys():\n",
    "        print('processing', song_index, end='\\r')\n",
    "        valence_dict, arousal_dict = va_dicts[song_index]\n",
    "        if len(valence_dict) != len(arousal_dict):\n",
    "            print(song_index, 'removed because of unmatched valence arousal sample count')\n",
    "            continue\n",
    "        timestamp_re = re.compile('[a-z_]+(\\d+)[a-z]')\n",
    "        key_mapping_func = lambda x: dict(sorted({int(timestamp_re.findall(key)[0]) / 1e3 : value for key, value in x.items()}.items()))\n",
    "        valence_dict, arousal_dict = key_mapping_func(valence_dict), key_mapping_func(arousal_dict)\n",
    "        song_feature_df = pd.read_csv(os.path.join(FEATURE_FILES_DIR, str(song_index) + '.csv'), sep=';').set_index('frameTime').filter(regex='mean$', axis=1)\n",
    "        try:\n",
    "            feature_dict = {timestamp : song_feature_df.loc[timestamp + t_shift(song_index)].to_numpy() for timestamp in valence_dict.keys()}\n",
    "        except KeyError:\n",
    "            print(song_index, 'removed because of csv key error')\n",
    "            continue\n",
    "        out_file[str(song_index) + '/features'] = np.array([*feature_dict.values()])\n",
    "        out_file[str(song_index) + '/valence'] = np.array([*valence_dict.values()]).reshape(-1, 1)\n",
    "        out_file[str(song_index) + '/arousal'] = np.array([*arousal_dict.values()]).reshape(-1, 1)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "with h5py.File(ARCHIVE_OUTPUT_PATH) as in_file:\n",
    "    for key in in_file.keys():\n",
    "        feature_list.append(np.array(in_file[key + '/features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# z-score normalization\n",
    "concatenated_matrix = np.concatenate(feature_list, axis=0)\n",
    "mean_vector = np.mean(concatenated_matrix, axis=0)\n",
    "std_vector = np.std(concatenated_matrix, axis=0)\n",
    "\n",
    "with h5py.File(ARCHIVE_OUTPUT_PATH) as in_file:\n",
    "    with h5py.File(NORMALIZED_ARCHIVE_OUTPUT_PATH) as out_file:\n",
    "        for key in in_file.keys():\n",
    "            sample_length = np.array(in_file[key + '/features']).shape[0]\n",
    "            mean_matrix, std_matrix = np.stack(mean_vector * sample_length), np.stack(std_vector * sample_length)\n",
    "            out_file[key + '/features'] = (np.array(in_file[key + '/features']) - mean_matrix) / std_matrix\n",
    "            out_file[key + '/valence'] = np.array(in_file[key + '/valence'])\n",
    "            out_file[key + '/arousal'] = np.array(in_file[key + '/arousal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# min-max normalization\n",
    "concatenated_matrix = np.concatenate(feature_list, axis=0)\n",
    "minimum_vector = np.min(concatenated_matrix, axis=0)\n",
    "maximum_vector = np.max(concatenated_matrix, axis=0)\n",
    "\n",
    "saved_features = None\n",
    "\n",
    "with h5py.File(ARCHIVE_OUTPUT_PATH) as in_file:\n",
    "    with h5py.File(NORMALIZED_ARCHIVE_OUTPUT_PATH) as out_file:\n",
    "        for key in in_file.keys():\n",
    "            sample_length = np.array(in_file[key + '/features']).shape[0]\n",
    "            min_matrix, max_matrix = np.stack([minimum_vector] * sample_length), np.stack([maximum_vector] * sample_length)\n",
    "            saved_features = np.array(in_file[key + '/features'])\n",
    "            out_file[key + '/features'] = (np.array(in_file[key + '/features']) - min_matrix) / (max_matrix - min_matrix)\n",
    "            out_file[key + '/valence'] = np.array(in_file[key + '/valence'])\n",
    "            out_file[key + '/arousal'] = np.array(in_file[key + '/arousal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitd9f33c60cf0741e28b54c6db950adecd",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}